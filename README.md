# md_legislation_ai

### ğŸ–¥ï¸ Pasul 3a: InterfaÈ›Äƒ Web (Gradio)

- âœ… Fisier: `app.py`
- âœ… InterfaÈ›Äƒ Gradio care acceptÄƒ Ã®ntrebÄƒri È™i returneazÄƒ rÄƒspunsuri legale Ã®n limba romÃ¢nÄƒ
- âœ… Rulat local la: http://localhost:7860

---

## ğŸš€ Cum rulezi proiectul

### 1. PorneÈ™te Chroma Server
```bash
docker-compose up -d
```

## Local environment
 - Legal area: Constitutia Republicii Moldova RO, EN
 - LLM model: RoMistral-7b-Instruct
 - Run: python, llama-cpp-python interface
 - Database: ChromaDB


## Production environment
 - LLM model: RoLlama3.1-8b-Instruct

## RAG Script logic
```bash
 1. Accept a question in Romanian
 2. Search Chroma for top 3 relevant legal chunks
 3. Format them as context
 4. Build a prompt like:
    ### Ãntrebare:
    [question]

    ### Context:
    1. [article 1]
    2. [article 2]
    3. [article 3]

    ### RÄƒspuns:
```
---

## ğŸ§© Rezumatul etapelor proiectului

### âœ… Pasul 1: Prelucrarea ConstituÈ›iei È™i cÄƒutare semanticÄƒ
- ğŸ“„ ÃncÄƒrcare fiÈ™ier PDF: ConstituÈ›ia Republicii Moldova
- âœ‚ï¸ Fragmentare Ã®n articole folosind LangChain
- ğŸ” Generare embeddings cu `intfloat/e5-large-v2`
- ğŸ—ƒï¸ Salvare vectori Ã®ntr-o colecÈ›ie Chroma: `Constitutia_2024_ro_chunks_e5`
- âœ… Testare cu interogÄƒri Ã®n limba romÃ¢nÄƒ folosind `test_search.py`

### âœ… Pasul 2: Integrarea LLM local (RAG complet)
- ğŸ§  Model ales: `RoMistral-7B-Instruct.Q4_K_M.gguf` (optimizat pentru romÃ¢nÄƒ)
- âš™ï¸ Inference local cu `llama-cpp-python`
- ğŸ”— Integrare cu Chroma: Ã®ntrebÄƒri â†’ context legal â†’ generare rÄƒspuns
- ğŸ§ª Script `rag_local.py`: funcÈ›ional, testat, produce rÄƒspunsuri coerente

### âœ… Pasul 3a: InterfaÈ›Äƒ web (UI)
- ğŸ–¥ï¸ UI construit cu Gradio (`app.py`)
- ğŸ›ï¸ InterfaÈ›Äƒ prietenoasÄƒ pentru Ã®ntrebÄƒri legale Ã®n romÃ¢nÄƒ
- âœ… Local, offline, fÄƒrÄƒ API extern
- âœ… Complet funcÈ›ional: Ã®ntrebare â†’ cÄƒutare â†’ generare â†’ afiÈ™are rÄƒspuns

### ğŸ”œ Pasul 3b: Input vocal
- ğŸ¤ Planificat: integrare Whisper sau Whisper.cpp
- Scop: utilizatorul poate pune Ã®ntrebÄƒri prin microfon

### ğŸ”œ Pasul 4: Extindere corpus legislativ
- ğŸ“š Codul Penal, Codul Civil, Monitorul Oficial etc.
- Va fi vectorizat È™i integrat Ã®n colecÈ›ii Chroma separate

### ğŸ”œ Pasul 5: Migrare pe VM avansat
- â˜ï¸ Mutarea sistemului pe o maÈ™inÄƒ virtualÄƒ performantÄƒ
- Scop: testare, demo public, scalabilitate

---
## Prompt example
```bash
A)  Ãntrebare
Contextul Ã®ntrebÄƒrilor se referÄƒ la Republica Moldova.
Poate PreÈ™edintele È›Äƒrii sÄƒ-È™i depunÄƒ demisia din propria iniÈ›iativÄƒ?
RÄƒspunsul sÄƒ conÈ›inÄƒ referinÈ›a la articolul din legislaÈ›ie.

B) CerinÈ›e faÈ›Äƒ de rÄƒspuns:
1) SÄƒ includÄƒ referinÈ›ele la legislaÈ›ie.
2) Verificare 
  - SÄƒ existe referinÈ›ele la articolele din legislaÈ›ie.
  - Se afiÈ™eazÄƒ doar articolele relevante la Ã®ntrebare.

C) Totalizare
 - La sfÃ®rÈ™it se adaogÄƒ o generalizare, luÃ®nd Ã®n considerare Ã®ntrebarea adresatÄƒ È™i informaÈ›ia gÄƒsitÄƒ.
```

## Notes
 - Chroma locks the embedding dimension at collection creation â€” and you can't mix or overwrite them.
 - If is used multiple users/sessions
```bash
with gr.Blocks() as demo:
    model_state = gr.State(embed_model)
    llm_state = gr.State(llm)
    
    submit.click(fn=answer_question, inputs=[question, model_state, llm_state], ...)
#   //But for now â€” global initialization at the top is enough for single-user local use.
```
 - Integrate FAISS with GPU acceleration
```bash
| Feature              | FAISS (GPU)       |
| -------------------- | ----------------- |
| Vector search speed  | âš¡ **Much faster** |
| Million-scale search | âœ… Easily scalable |
| GPU support          | âœ… CUDA-enabled    |
| Offline-compatible   | âœ… 100% local      |
```
